{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "catotron-inference.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfYHtg77kHuD",
        "colab_type": "text"
      },
      "source": [
        "# Conectar al vostre \"Google Drive\"\n",
        "Per sintetitzar les frases és a dir fer un \"inference\" necessitem els models de Tacotron2 i també del vocoder. La manera de fer-ho és a partir dels enllaços afegir els fitxers al vostre google drive.\n",
        "\n",
        "Un cop els fitxers estan a les nostres carpetes, podem donar els permisos a aquest \"notebook\" per accedir a les carpetes del drive. D'aquesta manera els fitxers seran visibles pel codi.\n",
        "\n",
        "Els enllaços són:\n",
        "* [Model de Catotron](https://drive.google.com/open?id=1-fdWV-aH5nIRv1rZKQYInsRes2At74xG\n",
        "), entrenat amb [Festcat](http://festcat.talp.cat/download.php) veu, Ona\n",
        "* [Model de Waveglow](https://drive.google.com/open?id=1WsibBTsuRg_SF2Z6L6NFRTT-NjEy1oTx), entrenat amb LJ Speech\n",
        "* [Model de MelGAN](https://drive.google.com/file/d/1U3LeuaMIVoRvMvfwlHjsRJPWhgTzeIBh/view), entrenat amb dades de Festcat\n",
        "* [Dades de Festcat](https://drive.google.com/open?id=1Mu5qxJovWzMRzXwHLdS2s69rDXhUzzB9\n",
        "); només la veu Pau, procecessat per Tacotron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zmuXnzmqdam",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!mkdir -p \"/content/drive/My Drive/tacotron_models\"\n",
        "!ls \"/content/drive/My Drive/tacotron_models\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ9mbj-sk5Fe",
        "colab_type": "text"
      },
      "source": [
        "# Importar el codi\n",
        "El \"notebook\" de colab ens deixa executar ordres del terminal d'un linux, mitjançant el `!` i `%`. A més, els servidors del colab venen amb certes aplicacions instal·lades com a CUDA i git.\n",
        "\n",
        "Per importar el codi, farem un clon de github."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJb50PNtq6EW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "!git clone https://github.com/collectivat-dev/tacotron2 catotron\n",
        "%cd catotron\n",
        "!git submodule init; git submodule update\n",
        "sys.path.append('/content/catotron/waveglow')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RUG0l0-otna_"
      },
      "source": [
        "# Instal·lació de les llibreries i cridar-les"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNHDsHk3sk-k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash\n",
        "pip install numpy scipy librosa unidecode inflect librosa tensorboardX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7m3iWqMAqrbf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "outputId": "8ffc166b-6e54-4fee-c85a-4d287b9359d2"
      },
      "source": [
        "# Generic libraries\n",
        "import matplotlib\n",
        "%matplotlib inline\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import IPython.display as ipd\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from audio_processing import griffin_lim\n",
        "\n",
        "# tacotron2 modules\n",
        "from hparams import create_hparams\n",
        "from model import Tacotron2\n",
        "from layers import TacotronSTFT, STFT\n",
        "\n",
        "import distributed\n",
        "from train import load_model\n",
        "from text import text_to_sequence\n",
        "#from denoiser import Denoiser"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js4lG53qo208",
        "colab_type": "text"
      },
      "source": [
        "# Carregar els models\n",
        "Per generar una veu, Tacotron2 necessita dos passos: el primer generar els mel espectrogrames i el segon generar les ones a partir dels espectrogrames. Per aquesta raó necessitem dos models un per Tacotron2 un altre pel Vocoder. En aquest cas un model de Waveglow.\n",
        "\n",
        "Amb aquest pas estem carregant els dos models a la memòria."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvhA4VeJJ4hU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparams = create_hparams()\n",
        "rate = 22050\n",
        "hparams.sampling_rate = rate\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/tacotron_models/upc_ona_tacotron2.pt\"\n",
        "model = load_model(hparams)\n",
        "model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
        "_ = model.cuda().eval().half()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTZ9nBfDKO0X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "waveglow_path = '/content/drive/My Drive/tacotron_models/waveglow_256channels_ljs_v2.pt'\n",
        "waveglow = torch.load(waveglow_path)['model']\n",
        "waveglow.cuda().eval().half()\n",
        "for k in waveglow.convinv:\n",
        "    k.float()\n",
        "#denoiser = Denoiser(waveglow)\n",
        "\n",
        "# fix for the \"AttributeError: 'ConvTranspose1d' object has no attribute 'padding_mode'\"\n",
        "for m in waveglow.modules():\n",
        "    if 'Conv' in str(type(m)):\n",
        "        setattr(m, 'padding_mode', 'zeros')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDiWvj93p5kS",
        "colab_type": "text"
      },
      "source": [
        "# Sintetitzar la veu\n",
        "\n",
        "Aquí introduirem un text, per generar la veu.\n",
        "\n",
        "Fixeu-vos la crida als dos models. Podem escoltar el resultat dins del \"notebook\" mitjançant el modul `ipython display`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQB0tffWM8Au",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# introduce the text\n",
        "text = \"En temps difícils, hem de veure els nostres èxits i augmentar el nostre coratge.\"\n",
        "\n",
        "# preprocessing\n",
        "sequence = np.array(text_to_sequence(text, ['catalan_cleaners']))[None, :]\n",
        "sequence = torch.from_numpy(sequence).to(device='cuda', dtype=torch.int64)\n",
        "\n",
        "# run the models\n",
        "mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "with torch.no_grad():\n",
        "    audio = waveglow.infer(mel_outputs_postnet)\n",
        "audio_numpy = audio[0].data.cpu().numpy()\n",
        "\n",
        "# make audio listenable\n",
        "ipd.Audio(audio_numpy, rate=rate)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COvB37AqhP6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p \"/content/drive/My Drive/test_wavs/\"\n",
        "audio_numpy /= np.max(np.abs(audio_numpy))\n",
        "write('/content/drive/My Drive/test_wavs/catotron_nvidia.wav', rate, audio_numpy.astype(np.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Osj697UxSaHy",
        "colab_type": "text"
      },
      "source": [
        "# Fer servir l'algorisme Griffin-Lim\n",
        "\n",
        "L'algorisme de Griffin-Lim facilita sintetitzar la veu sense la necessitat d'un vocoder entrenat per xarxes neuronals. Quan estem experimentant amb dades noves, i no tenim cap vocoder entrenat, aquest algorisme ajuda fer un control de qualitat ràpid. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTHmsuyHSrlj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def infer(checkpoint_path, griffin_iters, text):\n",
        "    hparams = create_hparams()\n",
        "    hparams.sampling_rate = 22050\n",
        "\n",
        "    model = load_model(hparams)\n",
        "    model.load_state_dict(torch.load(checkpoint_path)['state_dict'])\n",
        "    _ = model.cuda().eval()#.half()\n",
        "\n",
        "    sequence = np.array(text_to_sequence(text, ['catalan_cleaners']))[None, :]\n",
        "    sequence = torch.autograd.Variable(torch.from_numpy(sequence)).cuda().long()\n",
        "\n",
        "    mel_outputs, mel_outputs_postnet, _, alignments = model.inference(sequence)\n",
        "\n",
        "    taco_stft = TacotronSTFT(hparams.filter_length, hparams.hop_length, hparams.win_length, sampling_rate=hparams.sampling_rate)\n",
        "\n",
        "    mel_decompress = taco_stft.spectral_de_normalize(mel_outputs_postnet)\n",
        "    mel_decompress = mel_decompress.transpose(1, 2).data.cpu()\n",
        "    spec_from_mel_scaling = 1000\n",
        "    spec_from_mel = torch.mm(mel_decompress[0], taco_stft.mel_basis)\n",
        "    spec_from_mel = spec_from_mel.transpose(0, 1).unsqueeze(0)\n",
        "    spec_from_mel = spec_from_mel * spec_from_mel_scaling\n",
        "\n",
        "    audio = griffin_lim(torch.autograd.Variable(spec_from_mel[:, :, :-1]), taco_stft.stft_fn, griffin_iters)\n",
        "\n",
        "    audio = audio.squeeze()\n",
        "    audio = audio.cpu().numpy()\n",
        "    return audio\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-8ktbijSuXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "audio_griffin = infer(checkpoint_path, 60, text)\n",
        "ipd.Audio(audio_griffin, rate=rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xw-dK2oKTRok",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p \"/content/drive/My Drive/test_wavs/\"\n",
        "audio_griffin /= np.max(np.abs(audio_griffin))\n",
        "write('/content/drive/My Drive/test_wavs/catotron_griffin.wav', hparams.sampling_rate, audio_griffin)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9Fc71RlsSYU",
        "colab_type": "text"
      },
      "source": [
        "# Generar gràfiques\n",
        "\n",
        "Per donar una ullada a l'alineament i els espectrograma, fem servir matplotlib."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORy3mScPV6CV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_data(data, figsize=(16, 16)):\n",
        "    fig, axes = plt.subplots(len(data), 1, figsize=figsize)\n",
        "    for i in range(len(data)):\n",
        "        axes[i].imshow(data[i], aspect='auto', origin='bottom', \n",
        "                       interpolation='none')\n",
        "    plt.savefig('/content/result.png')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUtqtNNHob27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_data((mel_outputs.float().data.cpu().numpy()[0],\n",
        "           mel_outputs_postnet.float().data.cpu().numpy()[0],\n",
        "           alignments.float().data.cpu().numpy()[0].T))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBi-oBXtuFtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
